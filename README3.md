# Оценка эффективности алгоритмов сортировки и поиска

---

## 1. Алгоритм выбора наименьшего (Selection Sort)

**Как работает:**  
Алгоритм на каждом проходе ищет наименьший элемент в неотсортированной части массива и помещает его в начало этой части, меняя местами с текущим первым элементом.

**Характеристики выполнения:**  
- Внешний цикл проходит `n - 1` раз.
- Внутренний цикл на каждом шаге ищет минимум, уменьшая область поиска.
- Количество сравнений растёт квадратично с размером массива.

**Оценка сложности:**  
- **Худший / средний / лучший:** `O(n²)`  
- **Пояснение:** Количество операций сравнения определяется двойным циклом и составляет `n(n - 1) / 2`, что соответствует квадратичной зависимости от `n`.

---

## 2. Алгоритм сортировки пузырьком (Bubble Sort)

**Как работает:**  
Алгоритм многократно проходит по массиву, сравнивая пары соседних элементов. Если пара находится в неправильном порядке, элементы меняются местами. На каждом проходе наибольший элемент "всплывает" к концу.

**Характеристики выполнения:**  
- Внешний цикл: `for (i = 0; i < n - 1; i++)`
- Внутренний цикл: `for (j = 0; j < n - i - 1; j++)`
- Может быть оптимизирован: если за проход не произошло ни одного обмена, массив уже отсортирован.

**Оценка сложности:**  
- **Худший / средний:** `O(n²)`  
- **Лучший (отсортированный массив):** `O(n)`  
- **Пояснение:** В худшем случае — `n(n - 1) / 2` сравнений и обменов. В лучшем — только `n - 1` сравнений, если массив уже упорядочен.

---

## 3. Сортировка вставками (Insertion Sort)

**Как работает:**  
Алгоритм строит отсортированную часть массива слева направо. Каждый новый элемент из неотсортированной части вставляется в правильное место среди уже отсортированных.

**Характеристики выполнения:**  
- Внешний цикл: `for (i = 1; i < n; i++)`
- Внутренний цикл: `while (j >= 0 && arr[j] > key)` — сдвигает элементы вправо.
- Используется переменная `key` для хранения вставляемого значения.

**Оценка сложности:**  
- **Худший / средний:** `O(n²)`  
- **Лучший:** `O(n)`  
- **Пояснение:** В наихудшем случае (массив отсортирован в обратном порядке) каждый элемент нужно сравнить и сдвинуть, что приводит к квадратичной сложности. При уже отсортированном массиве — линейное время.

---

## 4. Сортировка слиянием (Merge Sort)

**Как работает:**  
Алгоритм рекурсивно делит массив на две равные (или почти равные) части до тех пор, пока не останутся подмассивы из одного элемента. Затем эти подмассивы объединяются (сливаются) в отсортированные блоки.

**Характеристики выполнения:**  
- Глубина рекурсии: `log₂ n`
- На каждом уровне рекурсии обрабатывается `n` элементов.
- Требует `O(n)` дополнительной памяти для временных массивов.

**Оценка сложности:**  
- **Все случаи:** `Θ(n log n)`  
- **Пояснение:** Независимо от начального состояния массива, количество уровней `log n`, и на каждом уровне `n` элементов. Это обеспечивает стабильную логарифмическую сложность.
- **Преимущества:** Устойчивость (не меняет относительный порядок равных элементов), предсказуемая производительность.

---

## 5. Сортировка Шелла (Shell Sort)

**Как работает:**  
Является улучшенной версией сортировки вставками. Сначала сортируются элементы, находящиеся на определённом расстоянии `gap`. Значение `gap` уменьшается по определённой схеме (например, `n/2, n/4, ..., 1`), и на последнем этапе выполняется обычная сортировка вставками.

**Характеристики выполнения:**  
- Внешний цикл уменьшает `gap`: `for (gap = n/2; gap > 0; gap /= 2)`
- Внутренние циклы обрабатывают подмассивы с текущим `gap`.

**Оценка сложности:**  
- **Зависит от последовательности `gap`:**
  - Классическая: `O(n²)`
  - Кнута: `O(n^(3/2))`
  - Оптимальные: `O(n log n)`
- **Пояснение:** Сложность определяется тем, насколько эффективно уменьшение `gap` устраняет инверсии в массиве.

---

## 6. Быстрая сортировка (Quick Sort)

**Как работает:**  
Алгоритм выбирает опорный элемент (pivot). Затем массив делится на две части: элементы, меньшие опоры, и элементы, большие или равные ей. Затем рекурсивно сортируются обе части.

**Характеристики выполнения:**  
- Процедура `partition` разбивает массив за `O(n)`.
- Глубина рекурсии варьируется от `log n` до `n`, в зависимости от баланса разбиения.

**Оценка сложности:**  
- **Средний случай:** `O(n log n)`  
- **Худший случай (например, отсортированный массив, неудачный выбор опоры):** `O(n²)`  
- **Пояснение:** При неудачном выборе опорного элемента разбиение может быть вырожденным (одна часть пуста), что приведёт к линейной глубине рекурсии и, как следствие, к квадратичной сложности.

---

## 7. Пирамидальная сортировка (Heapsort)

**Как работает:**  
Сначала из массива строится двоичная куча (max-heap). Затем максимальный элемент (корень кучи) извлекается и помещается в конец массива. Куча перестраивается, и процесс повторяется.

**Характеристики выполнения:**  
- Построение кучи: `O(n)`
- Извлечение `n` элементов: `n * O(log n)`

**Оценка сложности:**  
- **Все случаи:** `Θ(n log n)`  
- **Пояснение:** Построение кучи линейно, а `n` извлечений требуют `log n` операций на каждом.
- **Преимущество:** Работает in-place (без дополнительной памяти `O(n)` как у слияния).
- **Недостаток:** Неустойчивая (может изменить порядок равных элементов).

---

## 8. Линейный поиск (Linear Search)

**Как работает:**  
Алгоритм просматривает элементы массива один за другим, начиная с первого, и сравнивает каждый с искомым значением до тех пор, пока не найдёт совпадение или не дойдёт до конца.

**Характеристики выполнения:**  
- Не требует сортировки.
- Прост в реализации.

**Оценка сложности:**  
- **Все случаи:** `O(n)`  
- **Пояснение:** В худшем случае (элемент в конце или отсутствует) нужно проверить `n` элементов.

---

## 9. Двоичный (бинарный) поиск (Binary Search)

**Как работает:**  
Применяется **только** к **отсортированным** массивам. На каждом шаге текущая область поиска делится пополам. Искомое значение сравнивается с элементом в середине. В зависимости от результата, поиск продолжается в левой или правой половине.

**Характеристики выполнения:**  
- Требует предварительной сортировки.
- Использует два указателя (`left`, `right`) для границ поиска.

**Оценка сложности:**  
- **Худший / средний:** `O(log n)`  
- **Лучший (элемент сразу в середине):** `O(1)`  
- **Пояснение:** Размер области поиска уменьшается вдвое на каждом шаге, что приводит к логарифмической зависимости.

---

## 10. Интерполяционный поиск (Interpolation Search)

**Как работает:**  
Улучшенная версия двоичного поиска, эффективная для **отсортированных** массивов с **равномерным** распределением значений. Вместо деления пополам, позиция для проверки вычисляется с помощью **линейной интерполяции**, как будто значения расположены равномерно.

**Характеристики выполнения:**  
- Использует формулу: `pos = low + ((target - arr[low]) * (high - low)) / (arr[high] - arr[low])`
- Особенно эффективен при равномерном распределении.

**Оценка сложности:**  
- **При равномерном распределении:** `O(log log n)`  
- **В худшем случае (например, экспоненциальное распределение):** `O(n)`  
- **Лучший случай:** `O(1)`

---

## 11. Поиск по Фибоначчи (Fibonacci Search)

**Как работает:**  
Аналог бинарного поиска, но деление массива происходит не пополам, а в пропорциях, определяемых **последовательностью чисел Фибоначчи**. Это позволяет использовать только сложение и вычитание, а не деление.

**Характеристики выполнения:**  
- Использует числа Фибоначчи для определения точек разделения.
- Не требует деления, что может быть быстрее на некоторых архитектурах.

**Оценка сложности:**  
- **Все случаи:** `O(log n)`  
- **Пояснение:** Количество итераций пропорционально логарифму от индекса числа Фибоначчи, превышающего `n`.



